{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ffde6bd",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3f51e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,os\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Dense, Activation, Dropout, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125c0981",
   "metadata": {},
   "source": [
    "# Add data path and label the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5e2a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the file path where your dataset is stored\n",
    "data_path = r'C:\\Users\\admin\\Desktop\\face mask detection\\face-mask-detector\\dataset'\n",
    "categories = os.listdir(data_path)\n",
    "labels = [i for i in range(len(categories))]\n",
    "label_dict = dict(zip(categories,labels))\n",
    "print(label_dict)\n",
    "print(categories)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9161044c",
   "metadata": {},
   "source": [
    "# Make lists for data and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedc7572",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 150\n",
    "data = []\n",
    "target = []\n",
    "for category in categories:\n",
    "    folder_path = os.path.join(data_path,category) \n",
    "    img_names = os.listdir(folder_path)\n",
    "    \n",
    "    for img_name in img_names:\n",
    "        img_path = os.path.join(folder_path,img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        try:\n",
    "            gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            resized = cv2.resize(gray,(img_size,img_size))\n",
    "            data.append(resized)\n",
    "            target.append(label_dict[category])\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"Exception: \",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07632a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)/255.0  #data values are normalized\n",
    "#reshaping of data                                                data = np.reshape(data,(data.shape[0],img_size,img_size,1))\n",
    "target = np.array(target)\n",
    "new_target = np_utils.to_categorical(target)\n",
    "#saving the files                                \n",
    "np.save('data',data)\n",
    "np.save('target',new_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b409d4ca",
   "metadata": {},
   "source": [
    "# Build a Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad67acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data.npy')\n",
    "target = np.load('target.npy')\n",
    "model = Sequential()\n",
    "model.add(Conv2D(200,(3,3),input_shape=data.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(100,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c794619",
   "metadata": {},
   "source": [
    "# Split the data and target and fit into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9230ccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_target, test_target = train_test_split(data, target, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5142aa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint=ModelCheckpoint('model-{epoch:03d}.model', monitor='val_loss', verbose = 0, save_best_only = True,mode='auto')\n",
    "history = model.fit(train_data,train_target,epochs = 20, callbacks = [checkpoint], validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c800de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy plot\n",
    "plt.plot(history.history['acc'],'r',label='training accuracy')\n",
    "plt.plot(history.history['val_acc'],'b',label='validation accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5944d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss plot\n",
    "plt.plot(history.history['loss'],'r',label='training loss')\n",
    "plt.plot(history.history['val_loss'],'b',label='validation loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa1df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute on test data\n",
    "print(model.evaluate(test_data,test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a07a99",
   "metadata": {},
   "source": [
    "# Using the model in real-time through webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b6e703",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model-017.model') #load the best model\n",
    "faceCascade=cv2.CascadeClassifier(r'C:\\Users\\admin\\Desktop\\capstone\\HaarCascade\\haarcascade_frontalface_default.xml')\n",
    "video_capture = cv2.VideoCapture(0)  #starts the webcam\n",
    "labels_dict = {0:'NO MASK',1:'MASK'}\n",
    "color_dict  = { 0:(0,0,255),1:(0,255,0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7db450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    ret,frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(gray,1.3,5)\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        face_img = gray[y:y+w,x:x+h]\n",
    "        resized = cv2.resize(face_img,(img_size,img_size))\n",
    "        normalized = resized/255.0\n",
    "        reshaped = np.reshape(normalized,(1,img_size,img_size,1))\n",
    "        result = model.predict(reshaped)\n",
    "        \n",
    "        label = np.argmax(result,axis=1)[0]\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),color_dict[label],2)\n",
    "        cv2.putText(frame,labels_dict[label],(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "        \n",
    "    cv2.imshow('Video',frame)\n",
    "    key=cv2.waitKey(1)\n",
    "    \n",
    "    if(key==27):\n",
    "        break;\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "video_capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508ac131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f675c11c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80abbfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
